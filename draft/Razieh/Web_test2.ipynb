{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np \r\n",
    "import pandas as pd \r\n",
    "from selenium import webdriver\r\n",
    "\r\n",
    "## For opening a URL\r\n",
    "from urllib.request import urlopen\r\n",
    "## For fetching URLs\r\n",
    "from urllib.request import Request\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "HTTP is based on *requests and *responses - the *client makes requests and *servers send responses.\r\n",
    "urllib.request mirrors this with a (Request object) which represents the HTTP request you are making.\r\n",
    "In its simplest form *you create a (Request object) that specifies the URL you want to fetch. \r\n",
    "\r\n",
    "Calling *urlopen with this Request object returns a (response object) for the URL requested. \r\n",
    "This response is a file-like object, which means you can for example call .read() on the response\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "## Parse the html text\r\n",
    "from bs4 import BeautifulSoup as soup  \r\n",
    "\r\n",
    "import requests\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Fetch the webpage"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "### make the link\r\n",
    "my_url1 = \"https://www.ebay.com/itm/143010095641?hash=item214c10e219:g:XDgAAOSwBQ1df2wn\"\r\n",
    "my_url2 = \"https://www.ebay.com/itm/284151634665?hash=item4228c1dae9:g:bLoAAOSwLVdgBRBK\"\r\n",
    "\r\n",
    "my_url = [my_url1, my_url2]\r\n",
    "\r\n",
    "for link in my_url:\r\n",
    "    ### Create a Request object that specifies the URL you want to fetch\r\n",
    "    req = Request(link, headers={\"User-Agent\":\"Mozilla/5.0\"})\r\n",
    "\r\n",
    "    ### urlopen with this Request object returns a (response object) for the URL requested\r\n",
    "    webpage = urlopen(req).read()\r\n",
    "    #print(webpage)\r\n",
    "\r\n",
    "    ### The *Session object allows you to persist certain parameters across requests\r\n",
    "    #with requests.Session() as sess:\r\n",
    "        #print(sess)\r\n",
    "    clean_webpage = soup(webpage, 'html5lib')\r\n",
    "\r\n",
    "        ### The only difference is that find_all() returns a *list containing the single result, \r\n",
    "        ### and find() just returns the result.\r\n",
    "        ### If find_all() can’t find anything, it returns an empty list. \r\n",
    "        ### If find() can’t find anything, it returns None:\r\n",
    "    print(clean_webpage.find('span', attrs = {\"itemprop\" : \"price\"})['content'])\r\n",
    "    #print(clean_webpage)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "229.99\n",
      "455.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Google News: Trump"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "root = \"https://www.google.com/\"\r\n",
    "Url = \"https://www.google.com/search?q=trump&sxsrf=AOaemvK_WU3Jg_-9frJCGFlV51FN9HhqbQ:1632400167876&source=lnms&tbm=nws&sa=X&ved=2ahUKEwjMp4zBjJXzAhWNMewKHabzDhEQ_AUoAnoECAEQBA&biw=1536&bih=722&dpr=1.25\" \r\n",
    "\r\n",
    "req = Request(Url, headers={\"User-Agent\":\"Mozilla/5.0\"})\r\n",
    "page = urlopen(req).read()\r\n",
    "#with requests.Session() as sess:\r\n",
    "bs = soup(page, 'html5lib')\r\n",
    "#print(bs)\r\n",
    "\r\n",
    "## we needed to change the class for item, because class 'kCrYT' was too specific and \r\n",
    "## we needed to use th eparent class of this class.(check if object has this class.)\r\n",
    "for item in bs.find_all('div', attrs= { \"class\":\"ZINbbc xpd O9g5cc uUPGi\"}):\r\n",
    "    #print(item.find('a', href = True)['href'])\r\n",
    "    ## we split based on '&sa=U&' beacuse there is a problem by having it in the link \r\n",
    "    ## (when you click on the link, it says page is not available)\r\n",
    "    link = (item.find('a', href = True)['href'].split('/url?q=')[1]).split('&sa=U&')[0]\r\n",
    "    #print('The link is: {}'.format(link))\r\n",
    "    #print(\"yes\")\r\n",
    "    #print(item)\r\n",
    "    title = item.find('div', attrs = {'class':'BNeawe vvjwJb AP7Wnd'}).get_text()\r\n",
    "    ## We replcae (,) with nothing, beuse we wanted to save the information on CSV file\r\n",
    "    ## and CSV is sensitive to comma (,)\r\n",
    "    title = title.replace(\",\", \"\")\r\n",
    "    #print('title')\r\n",
    "    #print('The title is: {}'.format(title))\r\n",
    "    description = item.find('div', attrs = {'class':'BNeawe s3v9rd AP7Wnd'}).get_text()\r\n",
    "    ## We replcae (,) with nothing, beuse we wanted to save the information on CSV file\r\n",
    "    ## and CSV is sensitive to comma (,)\r\n",
    "    description = description.replace(\",\", \"\")\r\n",
    "\r\n",
    "    \r\n",
    "    #print(title)\r\n",
    "    time = description.split(\" · \")[0]\r\n",
    "    descrpt = description.split(\" · \")[1]\r\n",
    "    #print('description is: {}'.format(descrpt))\r\n",
    "    #print(\"time is: {}\".format(time))\r\n",
    "\r\n",
    "'''\r\n",
    "    ## a: read and write the file\r\n",
    "    document = open('trump_news.csv', 'a') \r\n",
    "    document.write(\"{}, {}, {}, {}, \\n\".format(title, time, descrpt, link))\r\n",
    "    document.close()\r\n",
    "'''"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n    ## a: read and write the file\\n    document = open(\\'trump_news.csv\\', \\'a\\') \\n    document.write(\"{}, {}, {}, {}, \\n\".format(title, time, descrpt, link))\\n    document.close()\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find the link of defined category in google news\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "root = \"https://news.google.com/\"\r\n",
    "#Url = \"https://www.google.com/search?q=trump&sxsrf=AOaemvK_WU3Jg_-9frJCGFlV51FN9HhqbQ:1632400167876&source=lnms&tbm=nws&sa=X&ved=2ahUKEwjMp4zBjJXzAhWNMewKHabzDhEQ_AUoAnoECAEQBA&biw=1536&bih=722&dpr=1.25\" \r\n",
    "new_url = 'https://news.google.com/topstories?hl=en-US&gl=US&ceid=US:en'\r\n",
    "\r\n",
    "req = Request(new_url, headers={\"User-Agent\":\"Mozilla/5.0\"})\r\n",
    "page = urlopen(req).read()\r\n",
    "#with requests.Session() as sess:\r\n",
    "bs = soup(page, 'html5lib')\r\n",
    "#print(bs)\r\n",
    "\r\n",
    "category = ['World', 'Business', 'Technology', 'Entertainment', 'Sports']\r\n",
    "category_link = []\r\n",
    "for element in category:\r\n",
    "    cat = bs.find('a', attrs = {'aria-label': element})\r\n",
    "    #print(category['href'])\r\n",
    "    link = root + str(cat['href'])\r\n",
    "    category_link.append(link)\r\n",
    "    #print(link)\r\n",
    "#print(category_link)\r\n",
    "\r\n",
    "\r\n",
    "################################ search in each page of category ################################\r\n",
    "for link in category_link:\r\n",
    "    Url = link\r\n",
    "\r\n",
    "    req = Request(Url, headers={\"User-Agent\":\"Mozilla/5.0\"})\r\n",
    "    page = urlopen(req).read()\r\n",
    "    #with requests.Session() as sess:\r\n",
    "    bs = soup(page, 'html5lib')\r\n",
    "    #print(bs)\r\n",
    "\r\n",
    "    i = 0\r\n",
    "    for item in bs.find_all('h3', attrs= { \"class\":\"ipQwMb ekueJc RD0gLb\"}):\r\n",
    "        if i >= 10:\r\n",
    "            break\r\n",
    "        else:\r\n",
    "            #print(\"I\")\r\n",
    "            #print(i)\r\n",
    "            first_article = item.find('a', attrs= {'class': \"DY5T1d RZIKme\"}) # DY5T1d RZIKme\r\n",
    "            #print(first_article.getText())\r\n",
    "            #print(first_article['href'])\r\n",
    "            new_link = root + str(first_article['href'])\r\n",
    "            title = first_article.getText()\r\n",
    "            title = title.replace(\",\", \"\")\r\n",
    "            time = bs.find('time', attrs={'class' :\"WW6dff uQIVzc Sksgp\"}).getText()\r\n",
    "            #print(title)\r\n",
    "            #print(time)\r\n",
    "            i = i + 1\r\n",
    "\r\n",
    "\r\n",
    "            document = open('news.csv', 'a') \r\n",
    "            document.write(\"{}, {}, {} \\n\".format(title, time, new_link))\r\n",
    "            document.close()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I\n",
      "0\n",
      "I\n",
      "1\n",
      "I\n",
      "2\n",
      "I\n",
      "3\n",
      "I\n",
      "4\n",
      "I\n",
      "5\n",
      "I\n",
      "6\n",
      "I\n",
      "7\n",
      "I\n",
      "8\n",
      "I\n",
      "9\n",
      "I\n",
      "0\n",
      "I\n",
      "1\n",
      "I\n",
      "2\n",
      "I\n",
      "3\n",
      "I\n",
      "4\n",
      "I\n",
      "5\n",
      "I\n",
      "6\n",
      "I\n",
      "7\n",
      "I\n",
      "8\n",
      "I\n",
      "9\n",
      "I\n",
      "0\n",
      "I\n",
      "1\n",
      "I\n",
      "2\n",
      "I\n",
      "3\n",
      "I\n",
      "4\n",
      "I\n",
      "5\n",
      "I\n",
      "6\n",
      "I\n",
      "7\n",
      "I\n",
      "8\n",
      "I\n",
      "9\n",
      "I\n",
      "0\n",
      "I\n",
      "1\n",
      "I\n",
      "2\n",
      "I\n",
      "3\n",
      "I\n",
      "4\n",
      "I\n",
      "5\n",
      "I\n",
      "6\n",
      "I\n",
      "7\n",
      "I\n",
      "8\n",
      "I\n",
      "9\n",
      "I\n",
      "0\n",
      "I\n",
      "1\n",
      "I\n",
      "2\n",
      "I\n",
      "3\n",
      "I\n",
      "4\n",
      "I\n",
      "5\n",
      "I\n",
      "6\n",
      "I\n",
      "7\n",
      "I\n",
      "8\n",
      "I\n",
      "9\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit ('web_scraper_project': venv)"
  },
  "interpreter": {
   "hash": "8c37c92801016ac181fcb687c8f1223a555cbdffe7647e67162abe27db884faa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}